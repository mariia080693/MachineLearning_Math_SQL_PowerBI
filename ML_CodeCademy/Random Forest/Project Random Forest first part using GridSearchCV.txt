import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Dataset loading and preparation
col_names = ['age', 'workclass', 'fnlwgt','education', 'education-num', 
             'marital-status', 'occupation', 'relationship', 'race', 'sex',
             'capital-gain','capital-loss', 'hours-per-week','native-country', 'income']
df = pd.read_csv('adult.data', header=None, names=col_names)

# Clean columns by stripping extra whitespace for columns of type "object"
df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

# Create feature dataframe X with feature columns and dummy variables for categorical features
feature_cols = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 
                'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 
                'hours-per-week', 'native-country'] # all but 'income'
X = pd.get_dummies(df[feature_cols], drop_first=True)

# Create output variable y which is binary, 0 when income is less than 50k, 1 when it is greater than 50k
y = df['income'].apply(lambda x: 1 if x == '>50K' else 0)

# Split data into a train and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# Instantiate random forest classifier
rf = RandomForestClassifier(random_state=42)

# Define the parameter grid to search over
param_grid = {'max_depth': range(1, 26)}

# Set up GridSearchCV to search over the max_depth values
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')

# Fit GridSearchCV to the training data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters and score
best_depth = grid_search.best_params_['max_depth']
best_score = grid_search.best_score_

print(f"Best max_depth: {best_depth}, Accuracy: {best_score:.4f}")

# Plot the accuracy scores for different depths using GridSearchCV results
train_scores = grid_search.cv_results_['mean_train_score']
test_scores = grid_search.cv_results_['mean_test_score']

plt.figure(figsize=(10, 5))
plt.plot(param_grid['max_depth'], train_scores, label="Train Accuracy", marker='o')
plt.plot(param_grid['max_depth'], test_scores, label="Test Accuracy", marker='s')
plt.xlabel("Max Depth")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Accuracy vs. Tree Depth (with GridSearchCV)")
plt.show()

# Refit the model using the best max_depth
best_rf = RandomForestClassifier(max_depth=best_depth, random_state=42)
best_rf.fit(X_train, y_train)

# Get feature importances and print the top 5
feature_importances = pd.DataFrame(best_rf.feature_importances_, index=X.columns, columns=["Importance"]).sort_values("Importance", ascending=False)
print("Top 5 Feature Importances:")
print(feature_importances.head())